name: "Text Extraction Action"
description: "Extracts text from PDFs and XMLs in processed bill data"

inputs:
  state:
    description: "State to process (2-letter abbreviation)"
    required: true
  github-token:
    description: "GitHub token for authentication"
    required: true
  force-update:
    description: "Force push changes even if there are upstream changes"
    required: false
    default: "false"

runs:
  using: "composite"
  steps:
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.13"

    - name: Install dependencies
      shell: bash
      working-directory: ${{ github.action_path }}/../..
      run: |
        python -m pip install --upgrade pip
        pip install pipenv
        pipenv install --deploy

    - name: Extract Text from PDFs and XMLs
      id: extract
      shell: bash
      working-directory: ${{ github.action_path }}/../..
      run: |
        echo "📄 Extracting text from PDFs and XMLs for ${{ inputs.state }}"

        # Check if the data directory exists in the calling repo (v2.0 structure)
        if [ ! -d "${{ github.workspace }}/country:us" ]; then
          echo "❌ Data directory not found: ${{ github.workspace }}/country:us"
          echo "Make sure the data pipeline has been run first"
          exit 1
        fi

        # Configure git for periodic commits
        cd "${{ github.workspace }}"
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        # Pull latest changes to ensure we have the most recent metadata with timestamps
        # This prevents race conditions where a previous run just committed updates
        echo "📥 Pulling latest changes to get updated metadata..."
        git pull origin main || {
          echo "⚠️ Pull failed, continuing with current checkout"
        }

        # Create a flag file to control the auto-commit loop
        touch /tmp/text_extraction_running

        # Start background process for periodic commits (every 30 minutes)
        (
          while [ -f /tmp/text_extraction_running ]; do
            sleep 1800  # 30 minutes

            if [ -f /tmp/text_extraction_running ]; then
              cd "${{ github.workspace }}"

              # Check if there are changes in country:us/ or .windycivi/
              if ! git diff --quiet country:us/ .windycivi/ 2>/dev/null || ! git diff --staged --quiet country:us/ .windycivi/ 2>/dev/null; then
                echo "⏰ [$(date)] Auto-committing progress to prevent data loss..."

                # Try to add files - if this fails, kill the main process
                if ! git add country:us/ .windycivi/ 2>&1; then
                  echo "::error::❌ CRITICAL: Failed to git add files during auto-commit!"
                  echo "::error::This means progress cannot be saved. Terminating job."
                  # Kill the main text extraction process
                  pkill -P $$ python || true
                  exit 1
                fi

                if ! git diff --staged --quiet; then
                  # Commit first (before pulling) to avoid "uncommitted changes" errors
                  git commit -m "🔄 Auto-save text extraction progress for ${{ inputs.state }} - $(date -u +%Y-%m-%dT%H:%M:%SZ)"

                  # Now pull and handle conflicts with merge strategy (not rebase)
                  # Rebase doesn't work well with concurrent auto-commits from multiple jobs
                  if ! git pull --no-rebase origin main 2>&1; then
                    echo "⚠️ Merge conflict detected, resolving intelligently..."

                    # Find all conflicted metadata.json files
                    CONFLICTED_FILES=$(git diff --name-only --diff-filter=U | grep metadata.json || true)

                    # For each conflicted metadata.json: preserve our _processing object
                    for file in $CONFLICTED_FILES; do
                      echo "  Resolving conflict in: $file"

                      # Extract our entire _processing object
                      OUR_PROCESSING=$(git show :2:"$file" | jq -c '.metadata._processing // empty' 2>/dev/null || echo "")

                      # Take scraper's version (has all the bill data updates)
                      git checkout --theirs "$file" || {
                        echo "::error::❌ Failed to checkout scraper's version of $file"
                        pkill -P $$ python || true
                        exit 1
                      }

                      # Re-inject our _processing object if it exists
                      if [ -n "$OUR_PROCESSING" ] && [ "$OUR_PROCESSING" != "null" ] && [ "$OUR_PROCESSING" != "empty" ]; then
                        jq --argjson proc "$OUR_PROCESSING" '.metadata._processing = $proc' "$file" > "$file.tmp" && mv "$file.tmp" "$file"
                        echo "  ✓ Preserved extraction metadata in $file"
                      fi
                    done

                    # Keep our files/ directories (extracted text content - always ours)
                    git checkout --ours "**/files/" 2>/dev/null || true

                    # Keep our .windycivi/ metadata
                    git checkout --ours .windycivi/ 2>/dev/null || true

                    git add -A
                    git commit --no-edit -m "🔄 Auto-merge: kept scraper data + extraction metadata + files"
                    echo "✅ Conflicts resolved intelligently"
                  fi

                  # Push with retries - if all fail, kill the job
                  PUSH_SUCCESS=false
                  for i in 1 2 3; do
                    if git push origin main 2>&1; then
                      echo "✅ Progress saved (attempt $i)"
                      PUSH_SUCCESS=true
                      break
                    else
                      echo "⚠️ Push failed (attempt $i), pulling and retrying..."
                      # Use merge strategy for concurrent updates
                      if ! git pull --no-rebase origin main 2>&1; then
                        # Resolve any conflicts intelligently
                        CONFLICTED_FILES=$(git diff --name-only --diff-filter=U | grep metadata.json || true)
                        for file in $CONFLICTED_FILES; do
                          OUR_PROCESSING=$(git show :2:"$file" | jq -c '.metadata._processing // empty' 2>/dev/null || echo "")
                          git checkout --theirs "$file" 2>/dev/null || true
                          if [ -n "$OUR_PROCESSING" ] && [ "$OUR_PROCESSING" != "null" ] && [ "$OUR_PROCESSING" != "empty" ]; then
                            jq --argjson proc "$OUR_PROCESSING" '.metadata._processing = $proc' "$file" > "$file.tmp" && mv "$file.tmp" "$file"
                          fi
                        done
                        git checkout --ours "**/files/" .windycivi/ 2>/dev/null || true
                        git add -A 2>/dev/null || true
                        git commit --no-edit -m "🔄 Auto-merge: kept scraper data + extraction metadata + files" 2>/dev/null || true
                      fi
                      sleep 5
                    fi
                  done

                  if [ "$PUSH_SUCCESS" = "false" ]; then
                    echo "::error::❌ CRITICAL: Failed to push after 3 attempts during auto-commit!"
                    echo "::error::Cannot save progress. Terminating job to prevent data loss."
                    pkill -P $$ python || true
                    exit 1
                  fi
                fi
              fi
            fi
          done
        ) &

        AUTO_COMMIT_PID=$!
        echo "🔄 Auto-commit process started (PID: $AUTO_COMMIT_PID)"

        # Change back to action directory to run Python
        cd "${{ github.action_path }}/../.."

        # Run text extraction using the main.py interface with incremental flag
        EXIT_CODE=0
        EXTRACTION_OUTPUT=$(pipenv run python text_extraction/main.py \
          --state "${{ inputs.state }}" \
          --data-folder "${{ github.workspace }}" \
          --output-folder "${{ github.workspace }}" \
          --incremental 2>&1) || EXIT_CODE=$?

        echo "$EXTRACTION_OUTPUT"

        # Stop the auto-commit background process
        rm -f /tmp/text_extraction_running
        wait $AUTO_COMMIT_PID 2>/dev/null || true

        # Extract summary statistics for GitHub Actions summary (take last match only)
        TOTAL_BILLS=$(echo "$EXTRACTION_OUTPUT" | grep -oP 'Total bills: \K\d+' | tail -1 || echo "0")
        PROCESSED=$(echo "$EXTRACTION_OUTPUT" | grep -oP 'Processed: \K\d+' | tail -1 || echo "0")
        SUCCESSFUL=$(echo "$EXTRACTION_OUTPUT" | grep -oP 'Successful: \K\d+' | tail -1 || echo "0")
        ERRORS=$(echo "$EXTRACTION_OUTPUT" | grep -oP 'Errors: \K\d+' | tail -1 || echo "0")
        SKIPPED=$(echo "$EXTRACTION_OUTPUT" | grep -oP 'Skipped \(already processed\): \K\d+' | tail -1 || echo "0")

        # Save stats to a file for easy display in caller workflow
        echo "📊 Text Extraction Summary for ${{ inputs.state }}" > "${{ github.workspace }}/.extraction_summary.txt"
        echo "========================================" >> "${{ github.workspace }}/.extraction_summary.txt"
        echo "" >> "${{ github.workspace }}/.extraction_summary.txt"
        echo "Total bills:                 $TOTAL_BILLS" >> "${{ github.workspace }}/.extraction_summary.txt"
        echo "Processed:                   $PROCESSED" >> "${{ github.workspace }}/.extraction_summary.txt"
        echo "Successful:                  $SUCCESSFUL" >> "${{ github.workspace }}/.extraction_summary.txt"
        echo "Errors:                      $ERRORS" >> "${{ github.workspace }}/.extraction_summary.txt"
        echo "Skipped (already processed): $SKIPPED" >> "${{ github.workspace }}/.extraction_summary.txt"

        # Create GitHub Actions summary
        {
          echo "## 📊 Text Extraction Summary for ${{ inputs.state }}"
          echo ""
          echo "| Metric | Count |"
          echo "|--------|-------|"
          echo "| Total Bills | $TOTAL_BILLS |"
          echo "| **Errors** | **$ERRORS** |"
          echo "| Processed | $PROCESSED |"
          echo "| Successful | $SUCCESSFUL |"
          echo "| Skipped | $SKIPPED |"
          echo ""
        } >> $GITHUB_STEP_SUMMARY

        if [ $EXIT_CODE -eq 0 ]; then
          echo "✅ **Status:** Complete" >> $GITHUB_STEP_SUMMARY
          echo "✅ Text extraction complete"
        else
          echo "⚠️ **Status:** Ended with exit code $EXIT_CODE" >> $GITHUB_STEP_SUMMARY
          echo "⚠️ Text extraction ended with code $EXIT_CODE (progress has been auto-saved)"
          exit $EXIT_CODE
        fi

    - name: Commit Changes
      shell: bash
      run: |
        echo "📝 Committing extracted text files"

        # Configure git
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

        # Add changes (bill text files in country:us/)
        git add country:us/ .windycivi/

        # Commit if there are changes
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          # Commit first (before pulling) to avoid "uncommitted changes" errors
          git commit -m "Extract text from PDFs/XMLs for ${{ inputs.state }} - $(date)"

          # Now pull and handle conflicts with merge strategy
          echo "📥 Pulling latest changes..."
          if ! git pull --no-rebase origin main 2>&1; then
            echo "⚠️ Merge conflict detected, resolving intelligently..."

            # Find all conflicted metadata.json files
            CONFLICTED_FILES=$(git diff --name-only --diff-filter=U | grep metadata.json || true)

            # For each conflicted metadata.json: preserve our _processing object
            for file in $CONFLICTED_FILES; do
              echo "  Resolving conflict in: $file"

              # Extract our entire _processing object
              OUR_PROCESSING=$(git show :2:"$file" | jq -c '.metadata._processing // empty' 2>/dev/null || echo "")

              # Take scraper's version (has all the bill data updates)
              git checkout --theirs "$file"

              # Re-inject our _processing object if it exists
              if [ -n "$OUR_PROCESSING" ] && [ "$OUR_PROCESSING" != "null" ] && [ "$OUR_PROCESSING" != "empty" ]; then
                jq --argjson proc "$OUR_PROCESSING" '.metadata._processing = $proc' "$file" > "$file.tmp" && mv "$file.tmp" "$file"
                echo "  ✓ Preserved extraction metadata in $file"
              fi
            done

            # Keep our files/ directories (extracted text content - always ours)
            git checkout --ours "**/files/" 2>/dev/null || true

            # Keep our .windycivi/ metadata
            git checkout --ours .windycivi/ 2>/dev/null || true

            git add -A
            git commit --no-edit -m "🔄 Auto-merge: kept scraper data + extraction metadata + files"
            echo "✅ Conflicts resolved intelligently"
          fi

          # Retry push up to 3 times in case of concurrent updates
          for i in 1 2 3; do
            if [ "${{ inputs.force-update }}" = "true" ]; then
              if git push --force-with-lease origin main; then
                echo "✅ Changes pushed successfully (attempt $i)"
                break
              fi
            else
              if git push origin main; then
                echo "✅ Changes pushed successfully (attempt $i)"
                break
              fi
            fi

            if [ $i -lt 3 ]; then
              echo "⚠️ Push failed (attempt $i), pulling and retrying..."
              # Use merge strategy for concurrent updates
              if ! git pull --no-rebase origin main 2>&1; then
                # Resolve conflicts intelligently
                CONFLICTED_FILES=$(git diff --name-only --diff-filter=U | grep metadata.json || true)
                for file in $CONFLICTED_FILES; do
                  OUR_PROCESSING=$(git show :2:"$file" | jq -c '.metadata._processing // empty' 2>/dev/null || echo "")
                  git checkout --theirs "$file" 2>/dev/null || true
                  if [ -n "$OUR_PROCESSING" ] && [ "$OUR_PROCESSING" != "null" ] && [ "$OUR_PROCESSING" != "empty" ]; then
                    jq --argjson proc "$OUR_PROCESSING" '.metadata._processing = $proc' "$file" > "$file.tmp" && mv "$file.tmp" "$file"
                  fi
                done
                git checkout --ours "**/files/" .windycivi/ 2>/dev/null || true
                git add -A 2>/dev/null || true
                git commit --no-edit -m "🔄 Auto-merge: kept scraper data + extraction metadata + files" 2>/dev/null || true
              fi
              sleep 2
            else
              echo "❌ Failed to push after 3 attempts"
              exit 1
            fi
          done

          echo "✅ Changes committed and pushed"
        fi
