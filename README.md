# OpenCivicData Blockchain Transformer

A GitHub Actions-powered pipeline that scrapes, formats, and extracts text from state and federal legislative data, organizing it into blockchain-style, versioned data structures.

## ğŸ—ï¸ Repository Structure

This repository provides **two composite actions** for processing legislative data:

```
â”œâ”€â”€ actions/
â”‚   â”œâ”€â”€ scrape/              # Scraping & Formatting Action
â”‚   â”‚   â””â”€â”€ action.yml       # Docker-based scraping + formatting
â”‚   â””â”€â”€ extract/             # Text Extraction Action
â”‚       â””â”€â”€ action.yml       # Extract text from PDFs/XMLs
â”œâ”€â”€ scrape_and_format/       # Scraping & formatting code
â”‚   â”œâ”€â”€ main.py              # Main entry point
â”‚   â”œâ”€â”€ handlers/            # Data handlers
â”‚   â”œâ”€â”€ postprocessors/      # Post-processing logic
â”‚   â””â”€â”€ utils/               # Utility functions
â”œâ”€â”€ text_extraction/         # Text extraction code
â”‚   â”œâ”€â”€ main.py              # Extraction entry point
â”‚   â””â”€â”€ utils/               # Extraction utilities
â”‚       â”œâ”€â”€ common.py        # Shared download & error tracking
â”‚       â”œâ”€â”€ xml_extractor.py # XML text extraction
â”‚       â”œâ”€â”€ html_extractor.py # HTML text extraction
â”‚       â””â”€â”€ pdf_extractor.py # PDF text extraction
â”œâ”€â”€ Pipfile                  # Python dependencies
â””â”€â”€ README.md
```

## ğŸš€ Composite Actions

### Action 1: Scrape & Format Data

**Purpose**: Scrapes legislative data from OpenStates and formats it into blockchain-style structure

**Features**:

- Docker-based scraping using OpenStates scrapers
- Nightly artifact creation (rolling + immutable archives)
- Automatic data formatting and organization
- Commits formatted data to calling repository

**Usage**:

```yaml
- uses: windy-civi/opencivicdata-blockchain-transformer/actions/scrape@main
  with:
    state: tn # State abbreviation (or 'usa' for federal)
    github-token: ${{ secrets.GITHUB_TOKEN }}
    use-scrape-cache: false # Optional: reuse cached data
    force-update: false # Optional: force push changes
```

### Action 2: Extract Text

**Purpose**: Extracts text from bill PDFs, XMLs, and HTMLs for analysis

**Features**:

- Extracts text from XML (structured bill text)
- Extracts text from HTML (web pages)
- Extracts text from PDF (with strikethrough detection)
- Saves both original files and extracted text
- Only processes bill versions (skips amendments to avoid blocking)

**Usage**:

```yaml
- uses: windy-civi/opencivicdata-blockchain-transformer/actions/extract@main
  with:
    state: tn # State abbreviation
    github-token: ${{ secrets.GITHUB_TOKEN }}
    force-update: false # Optional: force push changes
```

## ğŸ“‹ Complete Workflow Example

```yaml
name: Legislative Data Pipeline
on:
  schedule:
    - cron: "0 1 * * *" # Daily at 1 AM UTC
  workflow_dispatch:

jobs:
  scrape-and-format:
    name: Scrape & Format Data
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: windy-civi/opencivicdata-blockchain-transformer/actions/scrape@main
        with:
          state: tn
          github-token: ${{ secrets.GITHUB_TOKEN }}

  extract-text:
    name: Extract Bill Text
    runs-on: ubuntu-latest
    needs: scrape-and-format
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - uses: windy-civi/opencivicdata-blockchain-transformer/actions/extract@main
        with:
          state: tn
          github-token: ${{ secrets.GITHUB_TOKEN }}
```

## ğŸ”§ Setup

### Prerequisites

- Python 3.12+
- pipenv (for dependency management)
- Docker (for scraping action)

### Local Development

```bash
# Install dependencies
pipenv install

# Run scraping locally
pipenv run python scrape_and_format/main.py \
  --state tn \
  --openstates-data-folder ./data \
  --git-repo-folder ./output

# Run text extraction locally
pipenv run python text_extraction/main.py \
  --state tn \
  --data-folder ./data_output/data_processed \
  --output-folder ./output
```

## ğŸ“Š Output Format

### Scraping Output

Data is saved to `data_output/data_processed/`, organized by jurisdiction and session:

```
data_output/data_processed/
â””â”€â”€ country:us/
    â””â”€â”€ state:tn/
        â””â”€â”€ sessions/
            â””â”€â”€ 113/
                â””â”€â”€ bills/
                    â””â”€â”€ HB1234/
                        â”œâ”€â”€ metadata.json    # Bill metadata
                        â”œâ”€â”€ logs/            # Actions, events, votes
                        â””â”€â”€ files/           # Extracted text (if text extraction run)
```

### Text Extraction Output

For each bill version, creates:

- **Original file**: `BILLS-119hr1enr.xml` (or .html, .pdf)
- **Extracted text**: `BILLS-119hr1enr_extracted.txt`

Extracted text files include:

- Title and official title
- Number of sections
- Source information
- Full extracted text

### Error Tracking

Failed extractions are saved to `data_not_processed/text_extraction_errors/`:

- Individual error files per failed bill
- Summary reports with statistics
- Categorized by error type (download/parsing/save)

## ğŸ¯ Branches

- **`main`**: Stable production code
- **`refactor-text-extraction`**: Text extraction improvements
- **`backup-anti-blocking-code`**: Preserved complex anti-blocking code

## ğŸ“š Key Features

### Modular Text Extraction

- Separate extractors for XML, HTML, and PDF
- Shared download and error tracking utilities
- PDF strikethrough detection for legislative amendments
- Clean, maintainable code structure

### Smart Processing

- Only processes bill versions (actual text)
- Skips amendment documents (to avoid blocking)
- Prioritizes XML > HTML > PDF for best quality
- Handles multiple versions per bill

### Error Handling

- Comprehensive error tracking
- Individual error files for debugging
- Summary reports with statistics
- Continues processing on failures

## ğŸ’° Cost

- **Scraping**: Free (uses OpenStates Docker image)
- **Text Extraction**: Free (no external APIs)
- **GitHub Actions**: Free for public repos, included minutes for private repos

## ğŸ¤ Contributing

This is part of the Windy Civi project. For questions or improvements:

- Open an issue
- Submit a pull request
- Check the documentation in `project_docs/`

---

**Transform legislative data into actionable insights!** ğŸ›ï¸ğŸ“Š
