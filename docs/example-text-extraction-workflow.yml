# Example workflow for independent text extraction
# This runs separately from the scrape/format pipeline
# Typically scheduled to run a few hours after the main pipeline
#
# Features:
# - Incremental processing: only extracts text for new/updated bills
# - Auto-saves progress every 30 minutes to prevent data loss
# - Can be safely restarted if it times out - will continue from where it left off

name: "Text Extraction (Independent)"

on:
  schedule:
    - cron: "0 4 * * *" # Daily at 4 AM UTC (2 hours after scrape/format)
  workflow_dispatch:
    inputs:
      state:
        type: choice
        description: "State to process"
        required: true
        default: "wy"
        options:
          - wy
          - usa
          - il
          - tx
          - ny

jobs:
  extract-text:
    name: "ğŸ“„ Extract Text (Independent)"
    runs-on: ubuntu-latest
    permissions:
      contents: write
    timeout-minutes: 330 # 5.5 hours to stay under GitHub's 6-hour limit

    steps:
      - name: Checkout caller repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run text extraction action
        uses: windy-civi/opencivicdata-blockchain-transformer/actions/extract@main
        with:
          state: ${{ inputs.state || 'wy' }}
          github-token: ${{ secrets.GITHUB_TOKEN }}
          force-update: "false"

      - name: Display extraction summary
        shell: bash
        run: |
          echo "ğŸ“Š Text Extraction Summary:"
          echo "================================"
          echo "âœ… Text extraction completed successfully"
          echo "ğŸ“ Check the data_output/data_processed folder for extracted text files"
          echo "ğŸ” Look for *_extracted.txt files in the files/ directories"
