name: 'OpenStates Data Pipeline'
description: 'Complete pipeline to scrape, sanitize, and format OpenStates data'

inputs:
  state:
    description: 'State abbreviation (e.g., id, il, tx, ny)'
    required: true
  allow-session-fix:
    description: 'Allow interactive session fixes when session names are missing'
    required: false
    default: 'false'
  github-token:
    description: 'GitHub token for creating releases'
    required: true

runs:
  using: 'composite'
  steps:
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: "3.13"

    - name: Cache Scrapes
      uses: actions/cache@v4
      with:
        path: ${{ runner.temp }}/_working/_cache
        key: cache-scrapes-key-${{ github.run_id }}
        restore-keys: |
          cache-scrapes-key-

    - name: Clone and Build Scrapers from Source
      shell: bash
      run: |
        git clone https://github.com/openstates/openstates-scrapers.git
        cd openstates-scrapers
        docker build -t openstates/scrapers:dev .

    - name: Scrape Data
      shell: bash
      run: |
        mkdir -p ${RUNNER_TEMP}/_working
        docker run \
            -v "${RUNNER_TEMP}/_working/_data":/opt/openstates/openstates/_data \
            -v "${RUNNER_TEMP}/_working/_cache":/opt/openstates/openstates/_cache \
            openstates/scrapers:dev \
            $STATE bills --scrape --fastmode

    - name: Sanitize Data (removes _id and scraped_at)
      shell: bash
      run: |
        find ${RUNNER_TEMP}/_working/_data -type f -name "*.json" -exec bash -c 'jq "del(..|._id?, .scraped_at?)" "{}" > "{}.tmp" && mv "{}.tmp" "{}"' \;

    - name: Upload Sanitized Data as Release
      shell: bash
      env:
        GITHUB_TOKEN: ${{ inputs.github-token }}
      run: |
        # Create a zip file with all sanitized JSON files
        cd ${RUNNER_TEMP}/_working/_data/${{ inputs.state }}
        zip -r sanitized-data-${{ inputs.state }}.zip *.json
        
        # Create a release with the zip file
        gh release create "sanitized-data-${{ inputs.state }}-$(date +%Y%m%d-%H%M%S)" \
          --title "Sanitized OCD Data for ${{ inputs.state }}" \
          --notes "Sanitized OCD data for ${{ inputs.state }} state. Removed _id and scraped_at fields." \
          sanitized-data-${{ inputs.state }}.zip

    - name: Install dependencies
      shell: bash
      working-directory: ${{ github.workspace }}
      run: |
        pip install pipenv
        pipenv install --deploy

    - name: Format scraped data
      shell: bash
      working-directory: ./openstates_scraped_data_formatter
      env:
        FORMATTER_INPUT_FOLDER: ${{ runner.temp }}/_working/_data/${{ inputs.state }}
      run: |
        pipenv run python main.py \
          --state ${{ inputs.state }} \
          --input-folder ${{ runner.temp }}/_working/_data/${{ inputs.state }} \
          --allow-session-fix ${{ inputs.allow-session-fix }}

    - name: Upload Processed Data as Artifact
      uses: actions/upload-artifact@v4
      with:
        name: processed-data-${{ inputs.state }}
        path: data_output/